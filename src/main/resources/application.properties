# ===== Application Configuration =====
# Spring Boot application port
server.port=<local port>

# ===== Log Configuration =====
# Log level
logging.level.xyz.dreature.loat=debug

# ===== Langchain4j Configuration (AI integration using Ollama) =====
# Blocking chat model
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=qwen3:8b
langchain4j.ollama.chat-model.timeout=300s

# Streaming chat model
langchain4j.ollama.streaming-chat-model.base-url=http://localhost:11434
langchain4j.ollama.streaming-chat-model.model-name=qwen3:8b
langchain4j.ollama.streaming-chat-model.timeout=300s

