# ===== Application Configuration =====
# Spring Boot application port
server.port=<local port>

# ===== Log Configuration =====
# Log level
logging.level.xyz.dreature.loat=debug

# ===== Langchain4j Configuration (AI integration using Ollama) =====
# Blocking chat model
langchain4j.ollama.chat-model.base-url: http://localhost:11434
langchain4j.ollama.chat-model.model-name: deepseek-r1:8b
# Streaming chat model
langchain4j.ollama.streaming-chat-model.base-url: http://localhost:11434
langchain4j.ollama.streaming-chat-model.model-name: deepseek-r1:8b
